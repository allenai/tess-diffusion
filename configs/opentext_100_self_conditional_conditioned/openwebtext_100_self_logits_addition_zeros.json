{
	"model_name_or_path": "roberta-large",
	"per_device_train_batch_size": 40,
	"per_device_eval_batch_size": 48,
	"gradient_accumulation_steps": 8,
	"max_train_samples": 20000,
	"learning_rate": 3e-5,
	"weight_decay": 0.01,
	"num_warmup_steps": 2000,
	"tokenized_data_path": "${LOCAL_DIR}/simplex-diffusion/processed_data/openwebtext_100",
	"output_dir": "${LOCAL_DIR}/outputs/simplex/openwebtext_100_conditional_5k_train_2.5k_inference_self_logits_addition_zeros_conditioned",
	"checkpointing_steps": 1000,
	"max_seq_length": 100,
	"simplex_value": 5.0,
	"num_diffusion_steps": 5000,
	"num_inference_diffusion_steps": 2500,
	"line_by_line": true,
	"pad_to_max_length": false,
	"max_train_steps": 600000,
	"lr_scheduler_type": "cosine",
	"beta_schedule": "squaredcos_improved_ddpm",
	"top_p": 0.99,
	"self_condition": "logits_addition",
	"self_condition_zeros_after_softmax": true,
	"span_infilling": true,
	"mask_ratio": 0.5,
	"mean_mask_span_length": 10
}